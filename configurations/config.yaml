# Resume Parser and Recommender System Configuration

# LLM Provider for parsing resumes
llm_parser: gemini  # Options: gemini, azure

# Embedding model for vector generation
embd_model: sentence-transformers/all-mpnet-base-v2
embd_dimension: 768

# Data processing settings
num_professions: 5
num_cv_per_profession: 5
professions:
  - ACCOUNTANT
  - ADVOCATE
  - DESIGNER
  - FINANCE
  - HR
  # - ARTS
  # - CHEF
  # - FITNESS
  # - INFORMATION-TECHNOLOGY
  # - TEACHER

# Paths
resume_base_path: /workspaces/CV_parser_and_recommender/resume-dataset/data/data
jobs_base_path: /workspaces/CV_parser_and_recommender/data/sample_jobs

# CV Processing settings
batch_processing:
  num_workers: 4  # Number of parallel processes
  chunk_size: 5   # Resumes per batch

# Two-stage retrieval optimization (Task 4)
recommendation:
  use_two_stage: true           # Enable two-stage retrieval for efficiency
  stage1_top_k: 50              # Stage 1: Number of top similar jobs to filter
  stage1_threshold: 0.3         # Stage 1: Minimum similarity threshold (0.0-1.0)
  max_workers: 10               # Parallel workers for recommendation generation
  weights:                       # Scoring weights for different factors
    skills: 0.35
    experience: 0.25
    education: 0.15
    semantic: 0.25

# Redis Caching Configuration (Production Optimization)
redis:
  enabled: true                  # Enable Redis caching for embeddings
  host: localhost                # Redis server host
  port: 6379                     # Redis server port
  db: 0                          # Redis database number
  cache_ttl: 3600                # Cache TTL in seconds (1 hour)
  use_for_similarity: true       # Use cached embeddings for similarity computation (faster)
  # If false: Use Redis for caching but still use pgvector for similarity
  # If true: Use Redis + NumPy for similarity (10x faster, recommended for production)
